---
title: "nirmitin_FinalHomeworkCode_04"
author: "Nirmiti Naik"
date: "10/28/2021"
output: html_document
---

<br>
The stringr package is installed so that the command str_split() will work. 
```{r}
library(stringr)
library(curl)
library(ggplot2)
library(manipulate)
library(gridExtra)
library(lmodel2)
```

## **Challenge 1**
Write a simple R function, Z.prop.test(), that can perform one- or two-sample Z-tests for proportion data, using the following guidelines:

1) Your function should take the following arguments: p1 and n1 (no default) representing the estimated proportion and sample size (i.e., based on your sample data); p2 and n2 (both defaulting to NULL) that contain a second sample’s proportion and sample size data in the event of a two-sample test; p0 (no default) as the expected value for the population proportion; and alternative (default “two.sided”) and conf.level (default 0.95), to be used in the same way as in the function t.test().

2) When conducting a two-sample test, it should be p1 that is tested as being smaller or larger than p2 when alternative=“less” or alternative=“greater”, the same as in the use of x and y in the function t.test().

3) The function should perform a one-sample Z-test using p1, n1, and p0 if either p2 or n2 (or both) is NULL.

4) The function should contain a check for the rules of thumb we have talked about (n∗p>5 and n∗(1−p)>5) to ensure the validity of assuming the normal distribution in both the one- and two-sample settings. If this is violated, the function should still complete but it should also print an appropriate warning message.

5) The function should return a list containing the members Z (the test statistic), P (the appropriate p value), and CI (the two-sided CI with respect to “conf.level” around p1 in the case of a one-sample test and around p2-p1 in the case of a two-sample test). For all test alternatives (“two.sided”, “greater”, “less”), calculate symmetric CIs based on quantiles of the normal distribution rather than worrying about calculating single-limit confidence bounds.

<br> 
*My final challenge 1 has undergone serious changes since my original submission since I was able to reference the parts of resources my group found inspiration from (specifically module 10). Additionally, I was able to put the pieces of code that I had written to fulfill the sub-requirements together to have a function that actually runs. I feel like after exchanging commentary with my group and seeing how my peers approached the same challenge, my understanding of the actual challenge improved.*

*Relevant equations:*
*z-test = (xbar - mu)/(sd/sqrt(n)) &*
*validity check: ensure that (n∗p) > 5 and (n∗(1−p)) > 5*


```{r}
#fulfills requirement 1
Z.prop.test <- function(p1, n1, p2 = NULL, n2 = NULL, p0, alternative = c("two.sided", "less", "greater"), conf.level = 0.95) {
   
  #condition for one sample Z-test
  # fulfills requirement 3
  if(is.null(p2) | is.null(n2)) {
      # inspired by Frank's use of Module 10: classical hypothesis testing
      #m ~ pi
      mean <- mean(p1)
      stdev <- sd(p1)
      # 
      t <- t.test(x = p1, mu = p0, alternative = "two.sided")
      # t distribution based CIs
      lower <- m - qt(1 - 0.05/2, df = n - 1) * sem
      upper <- m + qt(1 - 0.05/2, df = n - 1) * sem
      ci <- c(lower, upper)
      ci
      t
      
      if (alternative == 'greater')
        p <- pnorm(z, lower.tail = FALSE)
      }
      
      if (alternative == 'less' ) { 
        p <-norm(z, lower.tail = TRUE)
      }
      #rule of thumb validity check
      #fulfills requirement 4
      if( (n1* m) < 5 & (n1*(1- m)) < 5){
        print("This isn't following a normal distribution") & print(t)
      }
        else {
          print(t)
        }
      }
  
  #condition for two sample Z-test          
  if(!is.null(p2) | !is.null(n2)) {
    # inspired by Frank's use of Module 10: classical hypothesis testing
    #phat ~ pi
    #fulfills requirement 2? 
    pstar <- (sum(p1) + sum(p2))/(length(p1) + length(p2))
    phat1 <- mean(p1)
    phat2 <- mean(p2)
    z <- (phat2 - phat1)/sqrt((pstar * (1 - pstar)) * (1/length(p1) + 1/length(p2)))
    p <- 1 - pnorm(z, lower.tail = TRUE) + pnorm(z, lower.tail = FALSE)
    pt <- prop.test(x = c(sum(p2), sum(p1)), n = c(length(p2), length(p1)), alternative = "two.sided", correct = FALSE)
    z
    p
    pt
    if (alternative == 'greater')
      p <- pnorm(z, lower.tail = FALSE)
    }
      
    if (alternative == 'less' ) { 
      p <-norm(z, lower.tail = TRUE)
    }
    #rule of thumb validity check
    #fulfills requirement 4
    if( (n1* phat1) < 5 & (n1*(1- phat1)) < 5 | (n2* phat2) < 5 & (n2*(1- phat2)) < 5){
        print("This isn't following a normal distribution") & print(t)
      }
        else {
          print(pt)
        }
      }
  }
```

*Looks like there may be a typo in the 2-sample part of your function that isn't allowing me to run it. p1 and p2 should just be proportions from the sample, and alternative="two.tailed", "less", or "greater" should be able to be defined in the function. It also looks like you defined z for a 2 sample but not 1 sample test. Also, the "if" part: if(is.null(p2) | is.null(n2)) should have an alternative "else" output that is for when there is a second sample (i.e p2 and n2 are not null). this may be what is disrupting the second part of the function.*

## **Challenge 2**
The dataset from Kamilar and Cooper has in it a large number of variables related to life history and body size. For this exercise, the end aim is to fit a simple linear regression model to predict longevity (MaxLongevity_m) measured in months from species’ brain size (Brain_Size_Species_Mean) measured in grams. Do the following for both longevity~brain size and log(longevity)~log(brain size):

*First, I will load the Kamilar and Cooper dataset.*
```{r}
f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN588_Fall21/KamilarAndCooperData.csv")
d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)
head(d)
```
<br>
**Fitting a linear regression model for longevity~brain size**
<br>
*Next, I will try to use the lm() function (which is used for fitting linear models) for longevity~brain size*
```{r}
lm <- lm(MaxLongevity_m ~ Brain_Size_Species_Mean, data = d)
lm

names(lm)
lm$coefficients
```

```{r}
head(lm$model)

g <- ggplot(data = d, aes(x = MaxLongevity_m, y = Brain_Size_Species_Mean))
g <- g + geom_point()
g <- g + geom_smooth(method = "lm", formula = y ~ x)
g
```

*Check your intercept in your model vs on your graph. do they match? stay consistent in what you use as x/y variables! -mel *


**Fitting a linear regression model for log(longevity)~log(brain size)**
<br>
*Now, I'll repeat the same code but for log(longevity)~log(brain size). It's interesting that this function removes rows containing "non-finite values and missing values). Visually, the confidence interval also looks wider for this graph.*
```{r}
loglm <- lm(log(MaxLongevity_m) ~ log(Brain_Size_Species_Mean), data = d)
loglm

names(loglm)
loglm$coefficients
```

```{r}
head(loglm$model)

g <- ggplot(data = d, aes(x = log(MaxLongevity_m), y = log(Brain_Size_Species_Mean)))
g <- g + geom_point()
g <- g + geom_smooth(method = "lm", formula = y ~ x)
g
```

**Identify and interpret the point estimate of the slope (β1), as well as the outcome of the test associated with the hypotheses H0: β1 = 0; HA: β1 ≠ 0.Also, find a 90 percent CI for the slope (β1) parameter.**
<br>
*Using the lm() functions and the summary() action called upon them, we can see that β1 ≠ 0 which allows us to reject the null hypothesis and accept the alternate hypothesis. The Pr(>|t|) is also much smaller than 0.05 (the p value used for statistical testing) which tells us that the differences in the data set are significant. β1lm > β1log(lm) but I'm not sure how to interpret this due to the nature of the adjusted slope of a log function.*

*The log transformed values can't be interpreted too much because you are completely changing the units to reduce the skew in your model -mel*

```{r}
summary(lm)

lmci <- confint(lm, level = 0.95)  # using the results of lm()
lmci

summary(loglm)

logci <- confint(loglm, level = 0.95)  # using the results of lm()
logci
```

**Using your model, add lines for the 90 percent confidence and prediction interval bands on the plot and add a legend to differentiate between the lines.**
<br>
*I've adapted code from Module 12 Challenge 5.*
```{r}
v <- seq(from = 0, to = 500, by = 1)
m <- lm(data = d, MaxLongevity_m ~ Brain_Size_Species_Mean)
ci <- predict(m, newdata = data.frame(Brain_Size_Species_Mean = v), interval = "confidence", level = 0.90)
pi <- predict(m, newdata = data.frame(Brain_Size_Species_Mean = v), interval = "prediction", level = 0.90)
plot(data = d, MaxLongevity_m ~ Brain_Size_Species_Mean)

lines(x = v, y = ci[, 1], col = "black")
lines(x = v, y = ci[, 2], col = "blue")
lines(x = v, y = ci[, 3], col = "blue")
lines(x = v, y = pi[, 2], col = "red")
lines(x = v, y = pi[, 3], col = "red")
```
*I'm not sure if the CI and PI interval lines have the right shape - I may have double logged one of the variables however when I remove both log calls on the x and y variables from either line 194 or 198, the lines disappear altogether.* 

*This looks good! You can also put the CIs and PIs from the predict() functions into a dataframe to be used by ggplot*


```{r}
v <- seq(from = 0, to = 500, by = 0.1)
m <- lm(data = d, log(MaxLongevity_m) ~ log(Brain_Size_Species_Mean))

ci <- predict(m, newdata = data.frame(Brain_Size_Species_Mean = v), interval = "confidence", level = 0.90)
pi <- predict(m, newdata = data.frame(Brain_Size_Species_Mean = v), interval = "prediction", level = 0.90)
plot(data = d, log(MaxLongevity_m) ~ log(Brain_Size_Species_Mean))

lines(x = v, y = ci[, 1], col = "black")
lines(x = v, y = ci[, 2], col = "blue")
lines(x = v, y = ci[, 3], col = "blue")
lines(x = v, y = pi[, 2], col = "red")
lines(x = v, y = pi[, 3], col = "red")
```

**Produce a point estimate and associated 90 percent PI for the longevity of a species whose brain weight is 800 gm. Do you trust the model to predict observations accurately for this value of the explanatory variable? Why or why not?**
<br>
*The model doesn't accurately predict the value of this explanatory variable since the possible range it gives (within the bounds of the confidence interval) is too wide to give an accurate prediction. This could be due to a lack of data for specimens with this brain weights in this range.*

```{r}
t <- coef(summary(lm))
t <- data.frame(unlist(t))
colnames(t) <- c("Est", "SE", "t", "p")
t

beta0 <- t$Est[1]
beta1 <- t$Est[2]
h_hat <- beta1 * 800 + beta0
h_hat

pi <- predict(lm, newdata = data.frame(Brain_Size_Species_Mean = 800), interval = "prediction",
    level = 0.90)  # for a single value
pi
```

*you can also directly put this value into the predict function -mel*

**Looking at your two models, which do you think is better? Why?**
<br>
*Overall, I think that the log lm model is better since the confidence intervals have a tighter fit - this is important since the confidence intervals hug the line of best fit. Therefore, having a more precise CI is valuable.*